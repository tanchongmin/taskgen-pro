{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1059f6-b56a-4c88-97ef-21fb80eaf139",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Memory\n",
    "\n",
    "- Memory is an integral part for an Agent - it enables an Agent to learn from previous experiences\n",
    "\n",
    "- Here, we implement our own memory class in order to store memory in a suitable abstraction space from any modality - text / image / video / audio into memory chunks or graphs, and extract out the relevant chunks or graph components based on the task\n",
    "\n",
    "- All Memory classes must implement MemoryTemplate, which contains the following core functions:\n",
    "    - `append`: Takes in a list of memories, processes them and adds it to memory chunk / graph\n",
    "    - `remove`: Takes in an existing memory and removes it\n",
    "    - `reset`: Removes all memories\n",
    "    - `retrieve`: Returns the top memories according to task\n",
    "    \n",
    "- Memory class can be used separately as part of a retrieval and storage pipeline that gets interfaced with the Agent via `Global Context` or directly into the task.\n",
    "\n",
    "- Memory can also be passed into the `Agent` class as part of the `memory_bank`. If done this way, Agents will automatically use the `retrieve` function each time a subtask is done to append the relevant memories into the agent prompt. Note all other functions need to be done separately outside the `Agent` class, so it is best done within Agent wrappers\n",
    "\n",
    "```python\n",
    "class MemoryTemplate(ABC):\n",
    "    \"\"\"A generic template provided for all memories\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def append(self, memory_list, mapper=None):\n",
    "        \"\"\"Appends multiple new memories\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def remove(self, existing_memory):\n",
    "        \"\"\"Removes an existing_memory. existing_memory can be str, or triplet if it is a Knowledge Graph\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        \"\"\"Clears all memories\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def retrieve(self, task: str):\n",
    "        \"\"\"Retrieves some memories according to task\"\"\"\n",
    "        pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaac9e6-5eed-4208-b934-0629ac09da03",
   "metadata": {},
   "source": [
    "## Some Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf2f8be-5b16-4341-aeef-6ea57662d6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from taskgen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6165e3-7652-4eff-a0af-96341e422a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Important: Make sure you do not commit your own API key\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR API KEY HERE>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064f9483-600d-4db7-bbc6-02fa9fc95303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm(system_prompt: str, user_prompt: str) -> str:\n",
    "    ''' Here, we use OpenAI for illustration, you can change it to your own LLM '''\n",
    "    # ensure your LLM imports are all within this function\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    # define your own LLM here\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c47ef0-5c64-4362-9fc9-105216cda1c3",
   "metadata": {},
   "source": [
    "## Define your Memory Class Here\n",
    "- Implement your Memory that overwrites all the required abstracted functions above\n",
    "- The default Memory Class will be for a Sync Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13e6fdd-dde6-4e8b-9552-50ce1cda405b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ListMemory(MemoryTemplate):\n",
    "    ''' Memory in the form of a list, retrieves using OpenAI embeddings '''\n",
    "    def __init__(self, memory_list: list = None, top_k: int = 3, database = None):\n",
    "        ''' Inputs:\n",
    "        memory_list: list of initial memories\n",
    "        top_k: Number of memories to retrieve\n",
    "        database: the mapping of memory to their embeddings\n",
    "        '''\n",
    "        self.top_k = top_k\n",
    "            \n",
    "        if memory_list is None:\n",
    "            self.memory_list = []\n",
    "        else:\n",
    "            self.memory_list = memory_list\n",
    "            \n",
    "        if database is None:\n",
    "            self.database = {}\n",
    "        else:\n",
    "            self.database = database\n",
    "\n",
    "    def append(self, memory_list, mapper=None):\n",
    "        \"\"\"Adds a list of memories\"\"\"\n",
    "        if not isinstance(memory_list, list):\n",
    "            memory_list = [memory_list]\n",
    "        self.memory_list.extend(memory_list)\n",
    "\n",
    "    def remove(self, memory_to_remove):\n",
    "        \"\"\"Removes a memory\"\"\"\n",
    "        self.memory.remove(memory_to_remove)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Clears all memory\"\"\"\n",
    "        self.memory_list = []\n",
    "        \n",
    "    def retrieve(self, task: str) -> list:\n",
    "        \"\"\"Performs retrieval of top_k similar memories according to embedding similarity\"\"\"\n",
    "        import heapq\n",
    "        import numpy as np\n",
    "        task_embedding = self.get_or_create_embedding(task)\n",
    "        memory_score = [np.dot(self.get_or_create_embedding(memory), task_embedding) for memory in self.memory_list]\n",
    "        top_k_indices = heapq.nlargest(self.top_k, range(len(self.memory_list)), key=lambda i: memory_score[i])\n",
    "        return [self.memory_list[index] for index in top_k_indices]\n",
    "        \n",
    "    def get_or_create_embedding(self, text):\n",
    "        if text in self.database:\n",
    "            return self.database[text]\n",
    "        else:\n",
    "            from openai import OpenAI\n",
    "            client = OpenAI()\n",
    "            cleaned_text = text.replace(\"\\n\", \" \")\n",
    "            embedding = client.embeddings.create(input=[cleaned_text], model=\"text-embedding-3-small\").data[0].embedding\n",
    "            self.database[text] = embedding\n",
    "            return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea0999a-b666-4df5-8d6c-bef6f8386493",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use Memory without the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e05b1769-9484-4d08-a7f7-091aedc69425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ListMemory(['hello', 'goodbye', 'good night', 'good morning'], top_k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd140e30-a97e-47f9-8b57-2ce6bb3eb5ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good morning']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.retrieve('good day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74263ed-b9c9-49e6-9ba5-53c8ed580765",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use Memory in an Agent's Memory Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5445510-9d8e-463c-a6f7-3235f33fcb18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greet_user(greeting: str) -> str:\n",
    "    ''' Outputs greeting to the user '''\n",
    "    return greeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bf6a466-066a-4919-b8a8-ddc1e483024e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent('Greeting Generator', 'Greets user with the greeting present in Greet_Memory', \n",
    "              llm = llm).assign_functions([greet_user])\n",
    "agent.memory_bank['Greet_Memory'] = ListMemory(['hello', 'goodbye', 'good night', 'good morning'], top_k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f44b898-882b-4744-8a4e-18fbb5894faa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet for the assigned task, which is to greet the user based on the context of a bright sunny day.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the assigned task, I can use the greeting stored in Greet_Memory, which is \"good morning\", as it is appropriate for a bright sunny day.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Use the greet_user function to output the greeting \"good morning\" to the user.\u001b[0m\n",
      "Calling function greet_user with parameters {'greeting': 'good morning'}\n",
      "> {'output_1': 'good morning'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The greeting \"good morning\" has been successfully generated and outputted to the user.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the greeting has been provided, the task appears to be complete. There is no further action required as the user has been greeted appropriately for the bright sunny day.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'good morning'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('It is a bright sunny day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd24dd-0d1d-4e26-b9e5-a9f6e604f96e",
   "metadata": {},
   "source": [
    "# Async Memory\n",
    "- Async memory is possible. Async memory must have async for the functions involving async processes\n",
    "- Start your Async memory class name with Async\n",
    "\n",
    "- **NOTE: When you contribute memory classes, it is not necessary to contribute the Async version**\n",
    "- **This is only for more production-based use cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0269645c-cdaa-43f4-8906-1d95026c55d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def llm_async(system_prompt: str, user_prompt: str):\n",
    "    ''' Here, we use OpenAI for illustration, you can change it to your own LLM '''\n",
    "    # ensure your LLM imports are all within this function\n",
    "    from openai import AsyncOpenAI\n",
    "    \n",
    "    # define your own LLM here\n",
    "    client = AsyncOpenAI()\n",
    "    response = await client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c63d37f6-5bd1-439f-b007-b990dbb8cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncListMemory(MemoryTemplate):\n",
    "    ''' Memory in the form of a list, retrieves using OpenAI embeddings '''\n",
    "    def __init__(self, memory_list: list = None, top_k: int = 3, database = None):\n",
    "        ''' Inputs:\n",
    "        memory_list: list of initial memories\n",
    "        top_k: Number of memories to retrieve\n",
    "        database: the mapping of memory to their embeddings\n",
    "        '''\n",
    "        self.top_k = top_k\n",
    "            \n",
    "        if memory_list is None:\n",
    "            self.memory_list = []\n",
    "        else:\n",
    "            self.memory_list = memory_list\n",
    "            \n",
    "        if database is None:\n",
    "            self.database = {}\n",
    "        else:\n",
    "            self.database = database\n",
    "\n",
    "    def append(self, memory_list, mapper=None):\n",
    "        \"\"\"Adds a list of memories\"\"\"\n",
    "        if not isinstance(memory_list, list):\n",
    "            memory_list = [memory_list]\n",
    "        self.memory_list.extend(memory_list)\n",
    "\n",
    "    def remove(self, memory_to_remove):\n",
    "        \"\"\"Removes a memory\"\"\"\n",
    "        self.memory.remove(memory_to_remove)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Clears all memory\"\"\"\n",
    "        self.memory_list = []\n",
    "        \n",
    "    async def retrieve(self, task: str) -> list:\n",
    "        \"\"\"Performs retrieval of top_k similar memories according to embedding similarity\"\"\"\n",
    "        import heapq\n",
    "        import numpy as np\n",
    "        import asyncio\n",
    "        task_embedding = await self.get_or_create_embedding(task)\n",
    "        # Await the coroutines to get the embeddings first\n",
    "        memory_embeddings = await asyncio.gather(*[self.get_or_create_embedding(memory) for memory in self.memory_list])\n",
    "        # Now, perform the dot product between each memory embedding and task_embedding\n",
    "        memory_score = [np.dot(memory_embedding, task_embedding) for memory_embedding in memory_embeddings]\n",
    "        top_k_indices = heapq.nlargest(self.top_k, range(len(self.memory_list)), key=lambda i: memory_score[i])\n",
    "        return [self.memory_list[index] for index in top_k_indices]\n",
    "        \n",
    "    async def get_or_create_embedding(self, text):\n",
    "        if text in self.database:\n",
    "            return self.database[text]\n",
    "        else:\n",
    "            from openai import AsyncOpenAI\n",
    "            client = AsyncOpenAI()\n",
    "            cleaned_text = text.replace(\"\\n\", \" \")\n",
    "            response = await client.embeddings.create(input=[cleaned_text], model=\"text-embedding-3-small\")\n",
    "            embedding = response.data[0].embedding\n",
    "            self.database[text] = embedding\n",
    "            return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4281d3b-1fbf-4ef2-919f-6877299c2627",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use Memory without the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "629a6f87-a6ff-4ea1-ae52-fe583b811594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = AsyncListMemory(['hello', 'goodbye', 'good night', 'good morning'], top_k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8b6aae0-40f0-4999-9f0f-78296d5b496a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good morning']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await memory.retrieve('good day')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b944be-80b0-463b-a600-ccca851c11b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use Memory in an Agent's Memory Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82bdfa0b-5949-4c71-8748-8821f08c86fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greet_user(greeting: str) -> str:\n",
    "    ''' Outputs greeting to the user '''\n",
    "    return greeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83aba781-932b-489a-bb0e-9785975457d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = AsyncAgent('Greeting Generator', 'Greets user with the greeting present in Greet_Memory', \n",
    "              llm = llm_async).assign_functions([greet_user])\n",
    "agent.memory_bank['Greet_Memory'] = AsyncListMemory(['hello', 'goodbye', 'good night', 'good morning'], top_k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4500ad4-000a-48b9-a486-83dee99e0d51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet for the assigned task, which is to greet the user based on the context of a bright sunny day.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the assigned task, I can use the greeting stored in Greet_Memory, which is \"good morning\", to greet the user appropriately.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Use the greet_user function to output the greeting \"good morning\" to the user.\u001b[0m\n",
      "Calling function greet_user with parameters {'greeting': 'good morning'}\n",
      "> {'output_1': 'good morning'}\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The greeting \"good morning\" has been successfully generated and outputted to the user.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the greeting has been provided, the next step is to determine if any further interaction or output is needed based on the context of a bright sunny day.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'output_1': 'good morning'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.run('It is a bright sunny day')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
