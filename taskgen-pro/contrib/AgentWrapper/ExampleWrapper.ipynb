{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1059f6-b56a-4c88-97ef-21fb80eaf139",
   "metadata": {},
   "source": [
    "# Wrappers\n",
    "\n",
    "- We use Wrappers to imbue additional functions / processes to Agents\n",
    "\n",
    "- Example of Wrappers:\n",
    "    - PlanningWrappers: How to plan and execute the plan, self-correct plan if there are any errors\n",
    "    - ReflectionWrappers: How to reflect upon what has been learned during task / across task and consolidate info for the next task\n",
    "    - VerifierWrappers: How to verify agent's outputs and correct them accordingly\n",
    "    - ConversationWrappers: How to converse with the agent\n",
    "    - MultiAgentWrappers: How multiple agents can converse with one another"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaac9e6-5eed-4208-b934-0629ac09da03",
   "metadata": {},
   "source": [
    "## Some Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edf2f8be-5b16-4341-aeef-6ea57662d6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from taskgen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6165e3-7652-4eff-a0af-96341e422a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Important: Make sure you do not commit your own API key\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR API KEY HERE>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "064f9483-600d-4db7-bbc6-02fa9fc95303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm(system_prompt: str, user_prompt: str) -> str:\n",
    "    ''' Here, we use OpenAI for illustration, you can change it to your own LLM '''\n",
    "    # ensure your LLM imports are all within this function\n",
    "    from openai import OpenAI\n",
    "    \n",
    "    # define your own LLM here\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature = 0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c47ef0-5c64-4362-9fc9-105216cda1c3",
   "metadata": {},
   "source": [
    "## Define your Wrapper Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e13e6fdd-dde6-4e8b-9552-50ce1cda405b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AgentWrapper(Agent):\n",
    "    ''' This class takes an Agent imbues it with additional functions\n",
    "    You can do everything the base Agent can do with this Wrapper '''\n",
    "    \n",
    "    def __init__(self, agent: Agent):\n",
    "        # Initialize the parent Agent\n",
    "        super().__init__(**agent.__dict__)  # Inherit all of the attributes of the passed agent\n",
    "        # Initiatlize the functions\n",
    "        self.assign_functions(list(agent.function_map.values()))\n",
    "        \n",
    "        ## Define Additional Variables as Needed\n",
    "        self.additional_variable = True\n",
    "       \n",
    "    ### Additional Functions Here - Modify these yourself ###\n",
    "    def answer(self, question, output_format = {'Answer': 'Concise Answer'}):\n",
    "        ''' This is an example function to answer based on subtasks completed\n",
    "        Note: This is just an example function, change it to whatever you want\n",
    "        \n",
    "        question (str): The question the user wants to ask\n",
    "        output_format (dict): The output format in a dictionary'''\n",
    "        return self.query(\n",
    "f'''Answer the following question according to the subtasks completed: ```{question}```\\n\n",
    "Subtasks Completed: ```{self.subtasks_completed}```\n",
    "Be concise and just give the answer with no explanation required.''', \n",
    "                               output_format = output_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6d8566-75fa-42fc-8542-9c87ef5c2cf0",
   "metadata": {},
   "source": [
    "## Show how the Wrapper is Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "916b81fa-2510-405f-89b3-6f573e86051a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = AgentWrapper(Agent('General Agent', 'Does Tasks', llm = llm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6c88056-51e9-476c-b060-79f585fdd344",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet for the assigned task of finding out 3+3.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: The task is straightforward and requires a simple calculation. Since the task is basic arithmetic, I can directly compute the result without needing to use a complex function.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Calculate the sum of 3 and 3.\u001b[0m\n",
      "Getting LLM to perform the following task: Calculate the sum of 3 and 3.\n",
      "> The assigned subtask was to calculate the sum of 3 and 3. By performing the addition operation, I combined the two numbers: 3 + 3. The result of this calculation is 6. Therefore, the detailed outcome of the task is that the sum of 3 and 3 equals 6.\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The assigned subtask of calculating the sum of 3 and 3 has been completed, resulting in the final answer of 6.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: Since the calculation is complete and the result is known, the next step is to finalize the task and provide the output to the user.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The assigned subtask was to calculate the sum of 3 and 3. By performing the addition operation, I combined the two numbers: 3 + 3. The result of this calculation is 6. Therefore, the detailed outcome of the task is that the sum of 3 and 3 equals 6.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('Find out 3+3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75fe7cb3-c818-40b3-821d-a188fe1f08d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Answer': 6}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default answer\n",
    "agent.answer('Give the final answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258cd1f6-f9da-4209-a8a9-4b368c407c11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Answer': 'six'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# customised answer in words\n",
    "agent.answer('Give the final answer', {'Answer': 'in words, type: str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2687863d-5094-44d3-bc04-fbc15bfeceb6",
   "metadata": {},
   "source": [
    "# Example: Conversation Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dda61187-43e0-4225-91fa-c115c7005b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "class ConversationWrapper(Agent):\n",
    "    ''' This class takes an Agent and allows for conversational-based interactions with User / another Agent / Environment. Also updates persistent memory with latest information in conversation\n",
    "    \n",
    "    - Inputs:\n",
    "        - **agent (compulsory)**: Agent. The agent we want to interact with\n",
    "        - **persistent_memory**: dict. What kinds of memory the agent should have that persist over the entire conversation and their descriptions. Uses the same format as `output_format` of `strict_json`.\n",
    "        - **person**: str. The name of the person you are talking to\n",
    "        - **conversation**: List. The current existing conversation. Default: None\n",
    "        - **num_past_conversation**: int. The number of past conversations to use for the agent\n",
    "        - **verbose**: bool. Default: True. Whether to print the Agent's inner states\n",
    "        \n",
    "    - ConversableAgent will automatically implement 3 new variables in `agent.shared_variables`:\n",
    "        - **Persistent Memory**: The memory that will be updated as the conversation goes along, defined in persistent_dict\n",
    "        - **Conversation**: The entire history of the conversation\n",
    "        - **Summary of Conversation**: A summary of the current conversation\n",
    "        \n",
    "    - ConversableAgent uses `chat()` which chats with the Agent and the Agent will perform actions and reply the chat message'''\n",
    "    \n",
    "    def __init__(self, agent: Agent, persistent_memory: dict = None, person = 'User', conversation = None, num_past_conversation: int = 5, verbose: bool = True):\n",
    "        # Initialize the parent Agent\n",
    "        super().__init__(**agent.__dict__)  # Inherit all of the attributes of the passed agent\n",
    "        # Initiatlize the functions\n",
    "        self.assign_functions(list(agent.function_map.values()))\n",
    "        \n",
    "        ## Define Additional Variables as Needed\n",
    "        self.persistent_memory = persistent_memory\n",
    "        self.num_past_conversation = num_past_conversation\n",
    "        self.person = person\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        ''' Define some external variables for the Agent '''\n",
    "        # add in the various types of memory\n",
    "        self.shared_variables['Persistent Memory'] = {}\n",
    "        # add in the conversation\n",
    "        if conversation is None:\n",
    "            self.shared_variables['Conversation'] = []\n",
    "        else:\n",
    "            self.shared_variables['Conversation'] = conversation\n",
    "        # add in the summary of conversation\n",
    "        self.shared_variables['Summary of Conversation'] = ''\n",
    "    \n",
    "    ## Reply the person\n",
    "    def chat(self, cur_msg):\n",
    "        ''' This does one chat with the person, firstly performing actions then replying the person, while updating the important memory '''\n",
    "        actions_done = []\n",
    "        \n",
    "        ## Do actions before replying person only if there are actions other than use_llm and end_task\n",
    "        my_actions = list(self.function_map.keys()) \n",
    "        if 'use_llm' in my_actions: my_actions.remove('use_llm')\n",
    "        if 'end_task' in my_actions: my_actions.remove('end_task')\n",
    "        if len(my_actions) > 0:\n",
    "            self.reset()\n",
    "            self.run(f'''Summary of Past Conversation: ```{self.shared_variables['Summary of Conversation']}```\n",
    "Past Conversation: ```{self.shared_variables['Conversation'][-self.num_past_conversation:]}```\n",
    "Latest input from {self.person}: ```{cur_msg}```\n",
    "Use Equipped Functions other than use_llm to help answer the latest input from {self.person}''',\n",
    "            )\n",
    "            \n",
    "            if len(self.subtasks_completed) > 0:\n",
    "                actions_done = self.reply_user('Summarise Subtasks Completed in one line', verbose = False)\n",
    "                print(colored(f'Actions Done: {actions_done}', 'red', attrs = ['bold']))\n",
    "                print()\n",
    "                self.reset()\n",
    "\n",
    "        ## Replies the person\n",
    "        res = self.query(f'''Summary of Past Conversation: ```{self.shared_variables['Summary of Conversation']}```\n",
    "Past Conversation: ```{self.shared_variables['Conversation'][-self.num_past_conversation:]}```\n",
    "Latest Input from {self.person}: ```{cur_msg}```\n",
    "Actions Done for Latest Input: ```{actions_done}```\n",
    "Persistent Memory: ```{self.shared_variables['Persistent Memory']}```\n",
    "Use Global Context and Conversation and Actions Done for Latest Input and and Persistent Memory as context when replying.\n",
    "\n",
    "First think through how to reply the latest message by {self.person}, before drafting the reply.\n",
    "{self.person} is not aware of Actions Done for Latest Input - include relevant information in your reply to {self.person}. Do not hallucinate actions.\n",
    "Thereafter, update the Summary of Conversation''', \n",
    "                          \n",
    "output_format = {\"Thoughts\": f\"How to reply\",\n",
    "                 f\"Reply to {self.person}\": f\"Your reply as {self.agent_name}\",\n",
    "                 \"Summary of Conversation\": \"Summarise key points of entire conversation in at most two sentences, building on previous Summary\"})\n",
    "        \n",
    "        # Update the Summary of Conversation and Append the conversation\n",
    "        self.shared_variables['Summary of Conversation'] = res['Summary of Conversation']\n",
    "        # Append information about user and actions to conversation\n",
    "        self.shared_variables['Conversation'].append(f'{self.person}: {cur_msg}')\n",
    "        self.shared_variables['Conversation'].append(f'{self.agent_name}: {res[f\"Reply to {self.person}\"]}')\n",
    "        \n",
    "        ## Update Persistent Memory\n",
    "        if self.persistent_memory is not None and self.persistent_memory != {}:\n",
    "            persistent_memory = strict_json(f'Update all fields of Persistent Memory based on information in Additional Conversation. Current value: ```{self.shared_variables[\"Persistent Memory\"]}```',\n",
    "               f'Additional Conversation\\n{self.person}: {cur_msg}\\n{self.agent_name}: {res[f\"Reply to {self.person}\"]}',\n",
    "               output_format = self.persistent_memory,\n",
    "               model = self.kwargs.get('model', 'gpt-4o-mini'),\n",
    "               llm = self.llm,\n",
    "               verbose = self.debug)\n",
    "                                                           \n",
    "            self.shared_variables[\"Persistent Memory\"] = persistent_memory\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(colored(f'Thoughts: {res[\"Thoughts\"]}', 'green', attrs = ['bold']))\n",
    "            print(colored(f'Persistent Memory: {self.shared_variables[\"Persistent Memory\"]}', 'blue', attrs = ['bold']))\n",
    "            print(colored(f'Summary of Conversation: {res[\"Summary of Conversation\"]}', 'magenta', attrs = ['bold']))\n",
    "        \n",
    "        return res[f'Reply to {self.person}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fd1274c-ee1e-49a8-8d50-76e14e3df82b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32mThoughts: The user has expressed happiness, which is a positive emotion. It’s important to acknowledge this feeling and encourage the user to share more about what is making them happy.\u001b[0m\n",
      "\u001b[1m\u001b[34mPersistent Memory: {'User Requests for the Conversation': 'User shared their happiness and was asked to elaborate on its source.', 'User Emotion': 'happy', 'Summary of Key Incidents': 'User expressed happiness and was encouraged to discuss its causes.'}\u001b[0m\n",
      "\u001b[1m\u001b[35mSummary of Conversation: The user expressed happiness, and I encouraged them to share more about the source of their positive feelings.\u001b[0m\n",
      "Psychology counsellor: I’m glad to hear that you are feeling happy! Would you like to share what’s contributing to your happiness today?\n",
      "\n",
      "\u001b[1m\u001b[32mThoughts: The user is expressing excitement about being able to work on TaskGen full-time, which likely contributes to their happiness. I should acknowledge this achievement and encourage them to share more about their plans or feelings regarding this new opportunity.\u001b[0m\n",
      "\u001b[1m\u001b[34mPersistent Memory: {'User Requests for the Conversation': 'User shared their ability to develop TaskGen full-time and was asked about their excitement and feelings regarding this new opportunity.', 'User Emotion': 'excited', 'Summary of Key Incidents': 'User expressed excitement about developing TaskGen full-time and was encouraged to share their feelings about this new chapter.'}\u001b[0m\n",
      "\u001b[1m\u001b[35mSummary of Conversation: The user expressed happiness about being able to develop TaskGen full-time, and I encouraged them to share more about their excitement and feelings regarding this new opportunity.\u001b[0m\n",
      "Psychology counsellor: That’s fantastic news! Being able to develop TaskGen full-time sounds like a wonderful opportunity. What aspects of this project are you most excited about, and how do you feel about this new chapter in your work?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the Agent\n",
    "agent = Agent('Psychology counsellor', \n",
    "              \"Helps to understand and respond to User's emotion and situation. Reply User based on User Requests for the Conversation\",\n",
    "             llm = llm)\n",
    "\n",
    "# Define the ConversationWrapper\n",
    "my_agent = ConversationWrapper(agent, \n",
    "             persistent_memory = {'User Requests for the Conversation': '',\n",
    "                             'User Emotion': '',\n",
    "                             'Summary of Key Incidents': \"Key incidents relevant to understanding User's situation in one line\"})\n",
    "\n",
    "# Set up the conversation\n",
    "# while True:\n",
    "#     user_input = input('User: ')\n",
    "#     if user_input == 'exit': break\n",
    "#     reply = my_agent.chat(user_input)\n",
    "#     print(my_agent.agent_name + ':', reply)\n",
    "#     print()\n",
    "\n",
    "# Simulate an example conversation\n",
    "user_input = 'I am happy'\n",
    "reply = my_agent.chat(user_input)\n",
    "print(my_agent.agent_name + ':', reply)\n",
    "print()\n",
    "\n",
    "user_input = 'I can develop TaskGen full-time now'\n",
    "reply = my_agent.chat(user_input)\n",
    "print(my_agent.agent_name + ':', reply)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81369ea6-bb44-4a62-918e-0f4954a23e2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User: I am happy',\n",
       " 'Psychology counsellor: I’m glad to hear that you are feeling happy! Would you like to share what’s contributing to your happiness today?',\n",
       " 'User: I can develop TaskGen full-time now',\n",
       " 'Psychology counsellor: That’s fantastic news! Being able to develop TaskGen full-time sounds like a wonderful opportunity. What aspects of this project are you most excited about, and how do you feel about this new chapter in your work?']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the agent's conversation so far\n",
    "my_agent.shared_variables['Conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81255544-e66e-4880-8514-beb5cff1b4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[30mObservation: No subtasks have been completed yet for the assigned task of writing a professional summary of the conversation.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the assigned task, I need to gather the key points and emotions expressed during the conversation to create a coherent summary.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: Utilize the equipped function to generate a general output that can help in summarizing the conversation based on the context provided.\u001b[0m\n",
      "Getting LLM to perform the following task: Utilize the equipped function to generate a general output that can help in summarizing the conversation based on the context provided.\n",
      "> The conversation has revolved around understanding the User's emotional state and the context of their situation. The User has expressed feelings of confusion and anxiety regarding a recent life change. It is important to acknowledge these emotions and validate the User's experiences. A summary of the conversation highlights the User's concerns about their future and the impact of their current situation on their mental well-being. Recommendations for coping strategies, such as mindfulness practices and seeking support from friends or professionals, have been discussed. Overall, the conversation aims to provide the User with clarity and reassurance, encouraging them to take proactive steps towards managing their emotions and navigating their circumstances.\n",
      "\n",
      "\u001b[1m\u001b[30mObservation: The conversation has revolved around understanding the User's emotional state and the context of their situation. The User has expressed feelings of confusion and anxiety regarding a recent life change. It is important to acknowledge these emotions and validate the User's experiences. A summary of the conversation highlights the User's concerns about their future and the impact of their current situation on their mental well-being. Recommendations for coping strategies, such as mindfulness practices and seeking support from friends or professionals, have been discussed. Overall, the conversation aims to provide the User with clarity and reassurance, encouraging them to take proactive steps towards managing their emotions and navigating their circumstances.\u001b[0m\n",
      "\u001b[1m\u001b[32mThoughts: To complete the remainder of the Assigned Task, I need to compile the insights and recommendations discussed during the conversation into a coherent professional summary that encapsulates the User's emotional state and the suggested coping strategies.\u001b[0m\n",
      "\u001b[1m\u001b[34mSubtask identified: End Task\u001b[0m\n",
      "Task completed successfully!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"The conversation has revolved around understanding the User's emotional state and the context of their situation. The User has expressed feelings of confusion and anxiety regarding a recent life change. It is important to acknowledge these emotions and validate the User's experiences. A summary of the conversation highlights the User's concerns about their future and the impact of their current situation on their mental well-being. Recommendations for coping strategies, such as mindfulness practices and seeking support from friends or professionals, have been discussed. Overall, the conversation aims to provide the User with clarity and reassurance, encouraging them to take proactive steps towards managing their emotions and navigating their circumstances.\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_agent.run('Write a professional summary of the conversation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1899b98-6a27-45cb-b1bc-755e292d5102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
